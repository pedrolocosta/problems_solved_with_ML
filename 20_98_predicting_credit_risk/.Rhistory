train.data <- credit.df[indexes,]
test.data <- credit.df[-indexes,]
# Feature Selection
library(caret)
library(randomForest)
# Função para seleção de variáveis
run.feature.selection <- function(num.iters=20, feature.vars, class.var){
set.seed(10)
variable.sizes <- 1:10
control <- rfeControl(functions = rfFuncs, method = "cv",
verbose = FALSE, returnResamp = "all",
number = num.iters)
results.rfe <- rfe(x = feature.vars, y = class.var,
sizes = variable.sizes,
rfeControl = control)
return(results.rfe)
}
# Executando a função
rfe.results <- run.feature.selection(feature.vars = train.data[,-1],
class.var = train.data[,1])
# Visualizando os resultados
rfe.results
varImp((rfe.results))
varImp((rfe.results))
# Criando e Avaliando o Modelo
library(caret)
library(ROCR)
# Biblioteca de utilitários para construção de gráficos
source("02.src/plot_utils.R")
## separate feature and class variables
test.feature.vars <- test.data[,-1]
test.class.var <- test.data[,1]
# Construindo um modelo de regressão logística
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
lr.model <- glm(formula = formula.init, data = train.data, family = "binomial")
# Visualizando o modelo
summary(lr.model)
# Testando o modelo nos dados de teste
lr.predictions <- predict(lr.model, test.data, type="response")
lr.predictions <- round(lr.predictions)
# Avaliando o modelo
confusionMatrix(table(data = lr.predictions, reference = test.class.var), positive = '1')
## Feature selection
formula <- "credit.rating ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = train.data, method = "glm", trControl = control)
importance <- varImp(model, scale = FALSE)
plot(importance)
# Construindo o modelo com as variáveis selecionadas
formula.new <- "credit.rating ~ account.balance + credit.purpose + previous.credit.payment.status + savings + credit.duration.months"
formula.new <- as.formula(formula.new)
lr.model.new <- glm(formula = formula.new, data = train.data, family = "binomial")
# Visualizando o modelo
summary(lr.model.new)
# Testando o modelo nos dados de teste
lr.predictions.new <- predict(lr.model.new, test.data, type = "response")
lr.predictions.new <- round(lr.predictions.new)
# Avaliando o modelo
confusionMatrix(table(data = lr.predictions.new, reference = test.class.var), positive = '1')
# Criando curvas ROC
lr.model.best <- lr.model
lr.prediction.values <- predict(lr.model.best, test.feature.vars, type = "response")
predictions <- prediction(lr.prediction.values, test.class.var)
par(mfrow = c(1,2))
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
?glm
df <- read.csv("01.dataset/credit_dataset.csv", header = TRUE, sep = ",")
head(df)
View(df)
Azure <- FALSE
# Execução de acordo com o valor da variável Azure
if(Azure){
source("src/plot_utils.R")
df <- maml.mapInputPort(1)
}else{
source("02.src/plot_utols.R")
df <- read.csv("01.dataset/credit.csv", sep = ",", header = T)
}
Azure <- FALSE
# Execução de acordo com o valor da variável Azure
if(Azure){
source("src/plot_utils.R")
df <- maml.mapInputPort(1)
}else{
source("02.src/plot_utils.R")
df <- read.csv("01.dataset/credit.csv", sep = ",", header = T)
}
# Exploratory data analysis
#-------------------------------------------------------------------------------
# general analysis -------------------------------------------------------------
head(df)                                                                        # initial data visualization
str(df)                                                                         # checking the types of variables
any(is.na(df))                                                                  # checking form missing values
# graphic presentation form missing values
#install.packages("Amelia")
library(Amelia)
missmap(df,
main = "Titanic Training Data - Mapa de Dados Missing",
col = c("yellow", "black"),
legend = FALSE)
summary(df)                                                                     # viewing statistical summary
Azure <- FALSE
if(Azure){
source("src/plot_utils.R")
source("src/ClassTools.R")
df <- maml.mapInputPort(1)
}else{
source("02.src/plot_utils.R")
source("02.src/ClassTools.R")
df <- read.csv("01.dataset/credit.csv", sep = ",", header = T)
}
library(ggplot2)
lapply(colNames2, function(x){
if(is.factor(df[,x])) {
ggplot(df, aes_string(x)) +
geom_bar() +
facet_grid(. ~ credit.rating) +
ggtitle(paste("Total de Credito Bom/Ruim por",x))}})
colnames(df)
library(ggplot2)
lapply(colnames(df), function(x){
if(is.factor(df[,x])) {
ggplot(df, aes_string(x)) +
geom_bar() +
facet_grid(. ~ credit.rating) +
ggtitle(paste("Total de Credito Bom/Ruim por",x))}})
library(ggplot2)
lapply(colnames(df), function(x){
if(is.integer(df[,x])) {
ggplot(df, aes_string(x)) +
geom_bar() +
facet_grid(. ~ credit.rating) +
ggtitle(paste("Taxa de crédito por",x))}})
methods <- c("pearson", "spearman")
# Aplicando os métodos de correlação com a função cor()
cors <- lapply(methods, function(method)
(cor(df[, cols], method = method)))
# Aplicando os métodos de correlação com a função cor()
cors <- lapply(methods, function(method)
(cor(df[, colnames(df)], method = method)))
# Preprando o plot
require(lattice)
plot.cors <- function(x, labs){
diag(x) <- 0.0
plot( levelplot(x,
main = paste("Plot de Correlação usando Método", labs),
scales = list(x = list(rot = 90), cex = 1.0)) )
}
# Mapa de Correlação
Map(plot.cors, cors, methods)
?map
png("03.analysis/Overview of the variables.png", width = 500, height = 500, res = 72)
lapply(colnames(df), function(x){
if(is.integer(df[,x])) {
ggplot(df, aes_string(x)) +
geom_bar() +
facet_grid(. ~ credit.rating) +
ggtitle(paste("Taxa de crédito por",x))}})
dev.off()
png("03.analysis/Correlation analysis.png", width = 500, height = 500, res = 72)
Map(plot.cors, cors, methods)
dev.off()
plot( levelplot("pearson",
main = paste("Pearson Correlation Analysis"),
scales = list(x = list(rot = 90), cex = 1.0)) )
methods <- c("pearson")
cors <- lapply(methods, function(method)
(cor(df[, colnames(df)], method = method)))
require(lattice)
plot.cors <- function(x, labs){
diag(x) <- 0.0
plot( levelplot(x,
main = paste("Correlation analysis using method", labs),
scales = list(x = list(rot = 90), cex = 1.0)) )
}
png("03.analysis/Correlation analysis.png", width = 500, height = 500, res = 72)
Map(plot.cors, cors, methods)                                                   # correlation maps
dev.off()
methods <- c("pearson", "spearman")
cors <- lapply(methods, function(method)
(cor(df[, colnames(df)], method = method)))
require(lattice)
plot.cors <- function(x, labs){
diag(x) <- 0.0
plot( levelplot(x,
main = paste("Correlation analysis using method", labs),
scales = list(x = list(rot = 90), cex = 1.0)) )
}
Map(plot.cors, cors, methods)
str(df)                                                                         # checking the types of variables
View(df)
df[[credit.amount ]]
to.factors <- function(df, variables){                                          # function to transform numeric variable in factor
for (variable in variables){
df[[variable]] <- as.factor(df[[variable]])
}
return(df)
}
scale.features <- function(df, variables){                                      # function to normalize the variables
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
numeric.vars <- c("credit.duration.months", "age", "credit.amount")             # listing the numeric variable
df <- scale.features(df, numeric.vars)                                          # applying the normalization
str(df)
categorical.vars <- c('credit.rating', 'account.balance',                       # listing the variables to be transformed
'previous.credit.payment.status', 'credit.purpose',
'savings', 'employment.duration', 'installment.rate',
'marital.status', 'guarantor', 'residence.duration',
'current.assets', 'other.credits', 'apartment.type',
'bank.credits', 'occupation', 'dependents', 'telephone',
'foreign.worker')
df <- to.factors(df = df, variables = categorical.vars)
str(df)
indexes <- sample(1:nrow(df), size = 0.6 * nrow(df))
indexes
df_train <- df[indexes,]
df_test <- df[-indexes,]
# Create a training and test data partition
#-------------------------------------------------------------------------------
?sample
# Preparation of the model using Feature Selection
#-------------------------------------------------------------------------------
library(caret)
library(randomForest)
# Função para seleção de variáveis
run.feature.selection <- function(num.iters=20, feature.vars, class.var){
variable.sizes <- 1:10
control <- rfeControl(functions = rfFuncs, method = "cv",
verbose = FALSE, returnResamp = "all",
number = num.iters)
results.rfe <- rfe(x = feature.vars, y = class.var,
sizes = variable.sizes,
rfeControl = control)
return(results.rfe)
}
# Executando a função
rfe.results <- run.feature.selection(feature.vars = df_train[,-1],
class.var = df_train[,1])
# Visualizando os resultados
rfe.results
varImp((rfe.results))
# Visualizando os resultados
rfe.results
test.data
?test.data
library(caret)
library(ROCR)
source("02.src/plot_utils.R")
?test.data
test.feature.vars <- df_test[,-1]                                               # separate feature and class variables
test.class.var <- df_test[,1]
View(test.class.var)
test_feature_vars <- df_test[,-1]                                               # separate feature and class variables
test_class_var <- df_test[,1]
methods <- c("pearson", "spearman")                                             # listing the methods
cors <- lapply(methods, function(method)                                        # correlating the method with the variables
(cor(df[, colnames(df)], method = method)))
require(lattice)
plot_cors <- function(x, labs){                                                 # associating the correlation to a plot
diag(x) <- 0.0
plot( levelplot(x,
main = paste("Correlation analysis using method", labs),
scales = list(x = list(rot = 90), cex = 1.0)) )
}
Map(plot_cors, cors, methods)
# normalizing the numeric variables --------------------------------------------
scale_features <- function(df, variables){                                      # function to normalize the variables
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
numeric_vars <- c("credit.duration.months", "age", "credit.amount")             # listing the numeric variable
df <- scale_features(df, numeric_vars)                                          # applying the normalization
str(df)                                                                         # checking the data frame
# converting variables to factor type (categorical) ----------------------------
to_factors <- function(df, variables){                                          # function to transform numeric variable in factor
for (variable in variables){
df[[variable]] <- as.factor(df[[variable]])
}
return(df)
}
categorical_vars <- c('credit.rating', 'account.balance',                       # listing the variables to be transformed
'previous.credit.payment.status', 'credit.purpose',
'savings', 'employment.duration', 'installment.rate',
'marital.status', 'guarantor', 'residence.duration',
'current.assets', 'other.credits', 'apartment.type',
'bank.credits', 'occupation', 'dependents', 'telephone',
'foreign.worker')
df <- to_factors(df = df, variables = categorical_vars)                         # applying the transformation
str(df)                                                                         # checking the data frame
library(caret)
library(randomForest)
run_feature_selection <- function(num_iters=20, feature_vars, class_var){       # function to list the most important variables
variable_sizes <- 1:10
control <- rfeControl(functions = rfFuncs, method = "cv",
verbose = FALSE, returnResamp = "all",
number = num_iters)
results_rfe <- rfe(x = feature_vars, y = class_var,
sizes = variable_sizes,
rfeControl = control)
return(results_rfe)
}
rfe_results <- run_feature.selection(feature_vars = df_train[,-1],              # applying the function
class_var = df_train[,1])
rfe_results                                                                     # viewing the results
varImp((rfe_results))
rfe_results <- run_feature_selection(feature_vars = df_train[,-1],              # applying the function
class_var = df_train[,1])
library(caret)
library(ROCR)
source("02.src/plot_utils.R")                                                   # utility library for building graphs
test_feature_vars <- df_test[,-1]                                               # separate feature and class variables
test_class_var <- df_test[,1]
formula_init <- "credit.rating ~ ."                                             # Building a logistic regression model
formula_init <- as_formula(formula_init)
lr_model <- glm(formula = formula_init, data = df_train, family = "binomial")
summary(lr_model)                                                               # viewing the model
formula_init <- "credit.rating ~ ."                                             # Building a logistic regression model
formula_init <- as.formula(formula_init)
lr_model <- glm(formula = formula_init, data = df_train, family = "binomial")
summary(lr_model)
model_ex <- glm(formula = formula_init, data = df_train, family = "binomial")
summary(model_ex)                                                               # viewing the model
# Testing the  model
#-------------------------------------------------------------------------------
# Testando o modelo nos dados de teste
model_ex_test <- predict(model_ex, df_test, type="response")
# Testing the  model
#-------------------------------------------------------------------------------
# Testando o modelo nos dados de teste
model_ex_test <- round(predict(model_ex, df_test, type="response"))
# Evaluating the model performance
#-------------------------------------------------------------------------------
confusionMatrix(table(data = model_ex_test, reference = test_class_var), positive = '1')
formula_init <- as.formula("credit.rating ~ .")
model_fs <- glm(formula = formula_init, data = df_train, family = "binomial")
summary(model_fs)                                                               # viewing the model
# Model optimization
#-------------------------------------------------------------------------------
formula <- as.formula("credit.rating ~ .")                                      # Feature selection
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model_v1 <- train(formula, data = df_train, method = "glm", trControl = control)# new model
summary(model_fs)                                                               # viewing the model
plot(importance)
importance <- varImp(model_v1, scale = FALSE)                                   # listing the most important variable
plot(importance)
varImp((rfe_results))
# Construindo o modelo com as variáveis selecionadas
formula.new <- "credit.rating ~ account.balance + credit.purpose +employment.duration + previous.credit.payment.status + marital.status"
test_feature_vars <- df_test[,-1]                                               # separate feature and class variables
test_class_var <- df_test[,1]
formula_init <- as.formula("credit.rating ~ .")                                 # Building a logistic regression model
model_v0 <- glm(formula = formula_init, data = df_train, family = "binomial")
summary(model_v0)
# Testing the  model
#-------------------------------------------------------------------------------
model_ex_test <- round(predict(model_ex, df_test, type="response"))             # testing the model_fs using test data
# Testing the  model
#-------------------------------------------------------------------------------
model_v0_test <- round(predict(model_ex, df_test, type="response"))             # testing the model_fs using test data
# Evaluating the model performance
#-------------------------------------------------------------------------------
confusionMatrix(table(data = model_ex_test, reference = test_class_var), positive = '1')
View(df)
View(test_feature_vars)
View(df_test)
# Criando curvas ROC
model_v0_test <- predict(model_v0, test_feature_vars, type = "response")
predictions <- prediction(model_v0_test, test_class_var)
test_class_var <- df_test[,1]
predictions <- prediction(model_v0_test, test_class_var)
# Creating and training a model
#-------------------------------------------------------------------------------
library(caret)
library(ROCR)
source("02.src/plot_utils.R")                                                   # utility library for building graphs
predictions <- prediction(model_v0_test, test_class_var)
par(mfrow = c(1,2))
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
png('Curva ROC model_v0', width=500, heigth=500, res=72)
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
dev.off()
png('04Curva ROC model_v0', width=500, heigth=500, res=72)
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
dev.off()
png('03.analysis/Curva_ROC_model_v0.png', width=500, heigth=500, res=72)
png('03.analysis/Curva_ROC_model_v0.png', width=500, height=500, res=72)
plot.roc.curve(predictions, title.text = "Curva ROC")
dev.off()
png('03.analysis/curva_precision-recall', width=500, height=500, res=72)
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
dev.off()
png('03.analysis/curva_precision-recall_model_v0', width=500, height=500, res=72)
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
dev.off()
png('03.analysis/model_v0-curva_ROC.png', width=500, height=500, res=72)
plot.roc.curve(predictions, title.text = "Curva ROC")
dev.off()
png('03.analysis/model_v0-curva_precision-recall.png', width=500, height=500, res=72)
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
dev.off()
Azure <- FALSE
if(Azure){
source("src/plot_utils.R")
source("src/ClassTools.R")
df <- maml.mapInputPort(1)
}else{
source("02.src/plot_utils.R")
source("02.src/ClassTools.R")
df <- read.csv("01.dataset/credit.csv", sep = ",", header = T)
}
# Exploratory data analysis
#-------------------------------------------------------------------------------
# general analysis -------------------------------------------------------------
head(df)                                                                        # initial data visualization
str(df)                                                                         # checking the types of variables
summary(df)                                                                     # viewing statistical summary
any(is.na(df))                                                                  # checking form missing values
View(df)
library(ggplot2)
lapply(colnames(df), function(x){                                               # overview of the variables
if(is.integer(df[,x])) {
ggplot(df, aes_string(x)) +
geom_bar() +
facet_grid(. ~ credit.rating) +
ggtitle(paste("Taxa de crédito por",x))}})
# correlation analysis ---------------------------------------------------------
methods <- c("pearson", "spearman")                                             # listing the methods
cors <- lapply(methods, function(method)                                        # correlating the method with the variables
(cor(df[, colnames(df)], method = method)))
require(lattice)
plot_cors <- function(x, labs){                                                 # associating the correlation to a plot
diag(x) <- 0.0
plot( levelplot(x,
main = paste("Correlation analysis using method", labs),
scales = list(x = list(rot = 90), cex = 1.0)) )
}
Map(plot_cors, cors, methods)                                                   # plotting the correlation maps
# Data Munging + Feature Engineering
#-------------------------------------------------------------------------------
# normalizing the numeric variables --------------------------------------------
scale_features <- function(df, variables){                                      # function to normalize the variables
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
numeric_vars <- c("credit.duration.months", "age", "credit.amount")             # listing the numeric variable
df <- scale_features(df, numeric_vars)                                          # applying the normalization
str(df)                                                                         # checking the data frame
# converting variables to factor type (categorical) ----------------------------
to_factors <- function(df, variables){                                          # function to transform numeric variable in factor
for (variable in variables){
df[[variable]] <- as.factor(df[[variable]])
}
return(df)
}
categorical_vars <- c('credit.rating', 'account.balance',                       # listing the variables to be transformed
'previous.credit.payment.status', 'credit.purpose',
'savings', 'employment.duration', 'installment.rate',
'marital.status', 'guarantor', 'residence.duration',
'current.assets', 'other.credits', 'apartment.type',
'bank.credits', 'occupation', 'dependents', 'telephone',
'foreign.worker')
df <- to_factors(df = df, variables = categorical_vars)                         # applying the transformation
str(df)                                                                         # checking the data frame
# Create a training and test data partition
#-------------------------------------------------------------------------------
indexes <- sample(1:nrow(df), size = 0.6 * nrow(df))
df_train <- df[indexes,]
df_test <- df[-indexes,]
# Creating and training a model
#-------------------------------------------------------------------------------
library(caret)
library(ROCR)
source("02.src/plot_utils.R")                                                   # utility library for building graphs
test_feature_vars <- df_test[,-1]                                               # separate feature and class variables
test_class_var <- df_test[,1]
formula_init <- as.formula("credit.rating ~ .")                                 # Building a logistic regression model
model_v0 <- glm(formula = formula_init, data = df_train, family = "binomial")
summary(model_v0)                                                               # viewing the model
# Testing the  model
#-------------------------------------------------------------------------------
model_v0_test <- round(predict(model_v0, df_test, type="response"))             # testing the model_fs using test data
# Evaluating the model performance
#-------------------------------------------------------------------------------
confusionMatrix(table(data = model_v0_test, reference = test_class_var), positive = '1')
model_v0_test <- predict(model_v0, test_feature_vars, type = "response")        # creating ROC curve
predictions <- prediction(model_v0_test, test_class_var)
par(mfrow = c(1,2))
png('03.analysis/model_v0-ROC_curve.png', width=500, height=500, res=72)
plot.roc.curve(predictions, title.text = "ROC curve")                           # plotting ROC curve
dev.off()
png('03.analysis/model_v0-precision-recall_curve.png', width=500, height=500,
res=72)
plot.pr.curve(predictions, title.text = "Precision/Recall curve")               # plotting Precision/Recall curve
dev.off()
if(Azure) {
maml.mapOutputPort('df')
} else {
write.csv(df, '01.dataset/df_01.csv')
}
